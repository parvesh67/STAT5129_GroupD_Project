if (!dir.exists(data_raw_dir)) dir.create(data_raw_dir)
# --- 2. Extract (import data) ---
# File info
file_name <- "yellow_tripdata_2024-01.parquet"
file_path <- file.path(data_raw_dir, file_name)
file_url <- "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet"
# Download if not present
if (!file.exists(file_path)) {
cat("Downloading file...\n")
GET(file_url, write_disk(file_path, overwrite = TRUE))
}
# Read parquet file
system.time(
taxi_df <- read_parquet(file_path)
)
# ---3. Quick checks ---
# Check file size
object.size(taxi_df)
format(object.size(taxi_df), units = "MB")
# Data structure
str(taxi_df)
summary(taxi_df)
nrow(taxi_df)
# Check missing values
colSums(is.na(taxi_df))
missing_values <- sum(is.na(taxi_df))
print(paste("Total missing values:", missing_values))
# --- 4. Transform (clean and combine)---
# Payment type summary & convert to descriptive labels---
payment_type_counts <- taxi_df %>%
count(payment_type) %>%
arrange(desc(n)) %>%
mutate(payment_type = factor(payment_type,
levels = c(1, 2, 3, 4),
labels = c("Credit Card", "Cash", "No Charge", "Dispute")))
print(payment_type_counts)
# --- Calculate trip duration---
taxi_df <- taxi_df %>%
mutate(
# Convert datetimes
tpep_pickup_datetime = as.POSIXct(tpep_pickup_datetime, format = "%Y-%m-%d %H:%M:%S"),
tpep_dropoff_datetime = as.POSIXct(tpep_dropoff_datetime, format = "%Y-%m-%d %H:%M:%S"),
# Calculate trip duration in minutes
trip_duration = as.numeric(difftime(tpep_dropoff_datetime, tpep_pickup_datetime, units = "mins"))
) %>%
select(tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count,
trip_distance, fare_amount, tip_amount, payment_type, trip_duration) %>%
filter(trip_distance > 0& trip_duration < 240)
head(taxi_df)
# Remove NA ---
taxi_df <- taxi_df %>%
na.omit()
# --- 5. Analyse ---
# --- Find peak hours ---
# Extracts the hour from the `tpep_pickup_datetime` column.
peak_hours_data <- taxi_df %>%
mutate(hour = hour(tpep_pickup_datetime)) %>%
group_by(hour) %>%
summarise(trip_count = n()) %>%
arrange(hour)
print(peak_hours_data, n = 24)
# --- 5.1. Identify peak and off-peak hours ---
peak_hour <- peak_hours_data %>% filter(trip_count == max(trip_count))
off_peak_hour <- peak_hours_data %>% filter(trip_count == min(trip_count))
cat("Peak hour:", peak_hour$hour, "o'clock with", peak_hour$trip_count, "trips\n")
cat("Off-peak hour:", off_peak_hour$hour, "o'clock with", off_peak_hour$trip_count, "trips\n")
# ---- 6. Load (save results) ----
dir.create("outputs", showWarnings = FALSE)
# Save cleaned data
write_parquet(taxi_df, "outputs/taxi_clean.parquet")
# Save model summary
capture.output(summary(taxi_df), file = "outputs/taxi_df.txt")
capture.output(print(peak_hours_data, n = 24), file = "outputs/peak_hours_data.txt")
capture.output(print(payment_type_counts), file = "outputs/payment_type_counts.txt")
# Export data peak hours as CSV
write_csv(peak_hours_data, "outputs/peak_hours_data.csv")
# --- 7. save plots ---
# Plot peak hours
png("outputs/peak_hour.png", width = 800, height = 600)
ggplot(peak_hours_data, aes(x = hour, y = trip_count)) +
geom_bar(stat = "identity", fill = "dodgerblue4") +
labs(
title = "NYC Taxi Trip Counts by Hour",
subtitle = "Peak hour plot",
x = "Hour of Day (24-hour clock)",
y = "Total Trip Count"
) +
scale_x_continuous(breaks = 0:23) +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold")) +
theme(axis.text.e=element_text (angle = 45.hjust =1)+
# ============================================================
# NYC Yellow Trip Data Analysis
# ============================================================
# --- 1. Install and load required packages ---
#install.packages(c("arrow", "dplyr", "ggplot2","lubridate","readr"))
library(arrow, quietly = TRUE, warn.conflicts = FALSE)		# for read_parquet() and write_parquet()
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)		# filter, group, summarize the data
library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)		# plots
library(lubridate, quietly = TRUE, warn.conflicts = FALSE)		# for extracting hours easily
library(readr, quietly = TRUE, warn.conflicts = FALSE)
# update this to your working directory
current_r_dir <- "C:/Users/vikgh/Desktop/STAT5129_GroupD_Project/R"
base_dir <- dirname(current_r_dir)
data_raw_dir <- file.path(base_dir, "data_raw")
# Ensure data_raw exists
if (!dir.exists(data_raw_dir)) dir.create(data_raw_dir)
# --- 2. Extract (import data) ---
# File info
file_name <- "yellow_tripdata_2024-01.parquet"
file_path <- file.path(data_raw_dir, file_name)
file_url <- "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet"
# Download if not present
if (!file.exists(file_path)) {
cat("Downloading file...\n")
GET(file_url, write_disk(file_path, overwrite = TRUE))
}
# Read parquet file
system.time(
taxi_df <- read_parquet(file_path)
)
# ---3. Quick checks ---
# Check file size
object.size(taxi_df)
format(object.size(taxi_df), units = "MB")
# Data structure
str(taxi_df)
summary(taxi_df)
nrow(taxi_df)
# Check missing values
colSums(is.na(taxi_df))
missing_values <- sum(is.na(taxi_df))
print(paste("Total missing values:", missing_values))
# --- 4. Transform (clean and combine)---
# Payment type summary & convert to descriptive labels---
payment_type_counts <- taxi_df %>%
count(payment_type) %>%
arrange(desc(n)) %>%
mutate(payment_type = factor(payment_type,
levels = c(1, 2, 3, 4),
labels = c("Credit Card", "Cash", "No Charge", "Dispute")))
print(payment_type_counts)
# --- Calculate trip duration---
taxi_df <- taxi_df %>%
mutate(
# Convert datetimes
tpep_pickup_datetime = as.POSIXct(tpep_pickup_datetime, format = "%Y-%m-%d %H:%M:%S"),
tpep_dropoff_datetime = as.POSIXct(tpep_dropoff_datetime, format = "%Y-%m-%d %H:%M:%S"),
# Calculate trip duration in minutes
trip_duration = as.numeric(difftime(tpep_dropoff_datetime, tpep_pickup_datetime, units = "mins"))
) %>%
select(tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count,
trip_distance, fare_amount, tip_amount, payment_type, trip_duration) %>%
filter(trip_distance > 0& trip_duration < 240)
head(taxi_df)
# Remove NA ---
taxi_df <- taxi_df %>%
na.omit()
# --- 5. Analyse ---
# --- Find peak hours ---
# Extracts the hour from the `tpep_pickup_datetime` column.
peak_hours_data <- taxi_df %>%
mutate(hour = hour(tpep_pickup_datetime)) %>%
group_by(hour) %>%
summarise(trip_count = n()) %>%
arrange(hour)
print(peak_hours_data, n = 24)
# --- 5.1. Identify peak and off-peak hours ---
peak_hour <- peak_hours_data %>% filter(trip_count == max(trip_count))
off_peak_hour <- peak_hours_data %>% filter(trip_count == min(trip_count))
cat("Peak hour:", peak_hour$hour, "o'clock with", peak_hour$trip_count, "trips\n")
cat("Off-peak hour:", off_peak_hour$hour, "o'clock with", off_peak_hour$trip_count, "trips\n")
# ---- 6. Load (save results) ----
dir.create("outputs", showWarnings = FALSE)
# Save cleaned data
write_parquet(taxi_df, "outputs/taxi_clean.parquet")
# Save model summary
capture.output(summary(taxi_df), file = "outputs/taxi_df.txt")
capture.output(print(peak_hours_data, n = 24), file = "outputs/peak_hours_data.txt")
capture.output(print(payment_type_counts), file = "outputs/payment_type_counts.txt")
# Export data peak hours as CSV
write_csv(peak_hours_data, "outputs/peak_hours_data.csv")
# --- 7. save plots ---
# Plot peak hours
png("outputs/peak_hour.png", width = 800, height = 600)
ggplot(peak_hours_data, aes(x = hour, y = trip_count)) +
geom_bar(stat = "identity", fill = "dodgerblue4") +
labs(
title = "NYC Taxi Trip Counts by Hour",
subtitle = "Peak hour plot",
x = "Hour of Day (24-hour clock)",
y = "Total Trip Count"
) +
scale_x_continuous(breaks = 0:23) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.text.x = element_text(angle = 45, hjust = 1)  # fixed
)
dev.off()
# Line plot
png("outputs/Trend across 24 Hrs.png", width = 600, height = 500)
ggplot(peak_hours_data, aes(x = hour, y = trip_count)) +
geom_line(linewidth = 1, color = "steelblue") +
geom_point(color = "steelblue") +
labs(
title = "Taxi Trip Counts by Hour of Day",
x = "Hour (0–23)",
y = "Number of Trips"
) +
theme_minimal()
# Close PNG device to save file
dev.off()
# Plot payment type
png("outputs/Payment_type.png", width = 600, height = 500)
ggplot(payment_type_counts, aes(x = payment_type, y = n, fill = payment_type)) +
geom_col() +   # geom_col() is simpler for pre-summarized data
labs(
title = "Distribution of Payment Types",
x = "Payment Type",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
dev.off()
# ============================================================
# NYC Yellow Trip Data Analysis
# ============================================================
# --- 1. Install and load required packages ---
#install.packages(c("arrow", "dplyr", "ggplot2","lubridate","readr"))
library(arrow, quietly = TRUE, warn.conflicts = FALSE)		# for read_parquet() and write_parquet()
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)		# filter, group, summarize the data
library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)		# plots
library(lubridate, quietly = TRUE, warn.conflicts = FALSE)		# for extracting hours easily
library(readr, quietly = TRUE, warn.conflicts = FALSE)
# update this to your working directory
current_r_dir <- "C:/Users/vikgh/Desktop/STAT5129_GroupD_Project/R"
base_dir <- dirname(current_r_dir)
data_raw_dir <- file.path(base_dir, "data_raw")
# Ensure data_raw exists
if (!dir.exists(data_raw_dir)) dir.create(data_raw_dir)
# --- 2. Extract (import data) ---
# File info
file_name <- "yellow_tripdata_2024-01.parquet"
file_path <- file.path(data_raw_dir, file_name)
file_url <- "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet"
# Download if not present
if (!file.exists(file_path)) {
cat("Downloading file...\n")
GET(file_url, write_disk(file_path, overwrite = TRUE))
}
# Read parquet file
system.time(
taxi_df <- read_parquet(file_path)
)
# ---3. Quick checks ---
# Check file size
object.size(taxi_df)
format(object.size(taxi_df), units = "MB")
# Data structure
str(taxi_df)
summary(taxi_df)
nrow(taxi_df)
# Check missing values
colSums(is.na(taxi_df))
missing_values <- sum(is.na(taxi_df))
print(paste("Total missing values:", missing_values))
# --- 4. Transform (clean and combine)---
# Payment type summary & convert to descriptive labels---
payment_type_counts <- taxi_df %>%
count(payment_type) %>%
arrange(desc(n)) %>%
mutate(payment_type = factor(payment_type,
levels = c(1, 2, 3, 4),
labels = c("Credit Card", "Cash", "No Charge", "Dispute")))
print(payment_type_counts)
# --- Calculate trip duration---
taxi_df <- taxi_df %>%
mutate(
# Convert datetimes
tpep_pickup_datetime = as.POSIXct(tpep_pickup_datetime, format = "%Y-%m-%d %H:%M:%S"),
tpep_dropoff_datetime = as.POSIXct(tpep_dropoff_datetime, format = "%Y-%m-%d %H:%M:%S"),
# Calculate trip duration in minutes
trip_duration = as.numeric(difftime(tpep_dropoff_datetime, tpep_pickup_datetime, units = "mins"))
) %>%
select(tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count,
trip_distance, fare_amount, tip_amount, payment_type, trip_duration) %>%
filter(trip_distance > 0& trip_duration < 240)
head(taxi_df)
# Remove NA ---
taxi_df <- taxi_df %>%
na.omit()
# --- 5. Analyse ---
# --- Find peak hours ---
# Extracts the hour from the `tpep_pickup_datetime` column.
peak_hours_data <- taxi_df %>%
mutate(hour = hour(tpep_pickup_datetime)) %>%
group_by(hour) %>%
summarise(trip_count = n()) %>%
arrange(hour)
print(peak_hours_data, n = 24)
# --- 5.1. Identify peak and off-peak hours ---
peak_hour <- peak_hours_data %>% filter(trip_count == max(trip_count))
off_peak_hour <- peak_hours_data %>% filter(trip_count == min(trip_count))
cat("Peak hour:", peak_hour$hour, "o'clock with", peak_hour$trip_count, "trips\n")
cat("Off-peak hour:", off_peak_hour$hour, "o'clock with", off_peak_hour$trip_count, "trips\n")
# ---- 6. Load (save results) ----
dir.create("outputs", showWarnings = FALSE)
# Save cleaned data
write_parquet(taxi_df, "outputs/taxi_clean.parquet")
# Save model summary
capture.output(summary(taxi_df), file = "outputs/taxi_df.txt")
capture.output(print(peak_hours_data, n = 24), file = "outputs/peak_hours_data.txt")
capture.output(print(payment_type_counts), file = "outputs/payment_type_counts.txt")
# Export data peak hours as CSV
write_csv(peak_hours_data, "outputs/peak_hours_data.csv")
# --- 7. save plots ---
# Plot peak hours
png("outputs/peak_hour.png", width = 800, height = 600)
ggplot(peak_hours_data, aes(x = hour, y = trip_count)) +
geom_bar(stat = "identity", fill = "dodgerblue4") +
labs(
title = "NYC Taxi Trip Counts by Hour",
subtitle = "Peak hour plot",
x = "Hour of Day (24-hour clock)",
y = "Total Trip Count"
) +
scale_x_continuous(breaks = 0:23) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.text.x = element_text(angle = 45, hjust = 1)  # fixed
)
dev.off()
# Line plot
png("outputs/Trend across 24 Hrs.png", width = 600, height = 500)
ggplot(peak_hours_data, aes(x = hour, y = trip_count)) +
geom_line(linewidth = 1, color = "steelblue") +
geom_point(color = "steelblue") +
labs(
title = "Taxi Trip Counts by Hour of Day",
x = "Hour (0–23)",
y = "Number of Trips"
) +
theme_minimal()
# Close PNG device to save file
dev.off()
# Plot payment type
png("outputs/Payment_type.png", width = 600, height = 500)
ggplot(payment_type_counts, aes(x = payment_type, y = n, fill = payment_type)) +
geom_col() +   # geom_col() is simpler for pre-summarized data
labs(
title = "Distribution of Payment Types",
x = "Payment Type",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
dev.off()
message("All outputs have been saved in \skills_demo_nyc\outputs")
# ============================================================
# NYC Yellow Trip Data Analysis
# ============================================================
# --- 1. Install and load required packages ---
#install.packages(c("arrow", "dplyr", "ggplot2","lubridate","readr"))
library(arrow, quietly = TRUE, warn.conflicts = FALSE)		# for read_parquet() and write_parquet()
library(dplyr, quietly = TRUE, warn.conflicts = FALSE)		# filter, group, summarize the data
library(ggplot2, quietly = TRUE, warn.conflicts = FALSE)		# plots
library(lubridate, quietly = TRUE, warn.conflicts = FALSE)		# for extracting hours easily
library(readr, quietly = TRUE, warn.conflicts = FALSE)
# update this to your working directory
current_r_dir <- "C:/Users/vikgh/Desktop/STAT5129_GroupD_Project/R"
base_dir <- dirname(current_r_dir)
data_raw_dir <- file.path(base_dir, "data_raw")
# Ensure data_raw exists
if (!dir.exists(data_raw_dir)) dir.create(data_raw_dir)
# --- 2. Extract (import data) ---
# File info
file_name <- "yellow_tripdata_2024-01.parquet"
file_path <- file.path(data_raw_dir, file_name)
file_url <- "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet"
# Download if not present
if (!file.exists(file_path)) {
cat("Downloading file...\n")
GET(file_url, write_disk(file_path, overwrite = TRUE))
}
# Read parquet file
system.time(
taxi_df <- read_parquet(file_path)
)
# ---3. Quick checks ---
# Check file size
object.size(taxi_df)
format(object.size(taxi_df), units = "MB")
# Data structure
str(taxi_df)
summary(taxi_df)
nrow(taxi_df)
# Check missing values
colSums(is.na(taxi_df))
missing_values <- sum(is.na(taxi_df))
print(paste("Total missing values:", missing_values))
# --- 4. Transform (clean and combine)---
# Payment type summary & convert to descriptive labels---
payment_type_counts <- taxi_df %>%
count(payment_type) %>%
arrange(desc(n)) %>%
mutate(payment_type = factor(payment_type,
levels = c(1, 2, 3, 4),
labels = c("Credit Card", "Cash", "No Charge", "Dispute")))
print(payment_type_counts)
# --- Calculate trip duration---
taxi_df <- taxi_df %>%
mutate(
# Convert datetimes
tpep_pickup_datetime = as.POSIXct(tpep_pickup_datetime, format = "%Y-%m-%d %H:%M:%S"),
tpep_dropoff_datetime = as.POSIXct(tpep_dropoff_datetime, format = "%Y-%m-%d %H:%M:%S"),
# Calculate trip duration in minutes
trip_duration = as.numeric(difftime(tpep_dropoff_datetime, tpep_pickup_datetime, units = "mins"))
) %>%
select(tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count,
trip_distance, fare_amount, tip_amount, payment_type, trip_duration) %>%
filter(trip_distance > 0& trip_duration < 240)
head(taxi_df)
# Remove NA ---
taxi_df <- taxi_df %>%
na.omit()
# --- 5. Analyse ---
# --- Find peak hours ---
# Extracts the hour from the `tpep_pickup_datetime` column.
peak_hours_data <- taxi_df %>%
mutate(hour = hour(tpep_pickup_datetime)) %>%
group_by(hour) %>%
summarise(trip_count = n()) %>%
arrange(hour)
print(peak_hours_data, n = 24)
# --- 5.1. Identify peak and off-peak hours ---
peak_hour <- peak_hours_data %>% filter(trip_count == max(trip_count))
off_peak_hour <- peak_hours_data %>% filter(trip_count == min(trip_count))
cat("Peak hour:", peak_hour$hour, "o'clock with", peak_hour$trip_count, "trips\n")
cat("Off-peak hour:", off_peak_hour$hour, "o'clock with", off_peak_hour$trip_count, "trips\n")
# ---- 6. Load (save results) ----
dir.create("outputs", showWarnings = FALSE)
# Save cleaned data
write_parquet(taxi_df, "outputs/taxi_clean.parquet")
# Save model summary
capture.output(summary(taxi_df), file = "outputs/taxi_df.txt")
capture.output(print(peak_hours_data, n = 24), file = "outputs/peak_hours_data.txt")
capture.output(print(payment_type_counts), file = "outputs/payment_type_counts.txt")
# Export data peak hours as CSV
write_csv(peak_hours_data, "outputs/peak_hours_data.csv")
# --- 7. save plots ---
# Plot peak hours
png("outputs/peak_hour.png", width = 800, height = 600)
ggplot(peak_hours_data, aes(x = hour, y = trip_count)) +
geom_bar(stat = "identity", fill = "dodgerblue4") +
labs(
title = "NYC Taxi Trip Counts by Hour",
subtitle = "Peak hour plot",
x = "Hour of Day (24-hour clock)",
y = "Total Trip Count"
) +
scale_x_continuous(breaks = 0:23) +
theme_minimal() +
theme(
plot.title = element_text(hjust = 0.5, face = "bold"),
axis.text.x = element_text(angle = 45, hjust = 1)  # fixed
)
dev.off()
# Line plot
png("outputs/Trend across 24 Hrs.png", width = 600, height = 500)
ggplot(peak_hours_data, aes(x = hour, y = trip_count)) +
geom_line(linewidth = 1, color = "steelblue") +
geom_point(color = "steelblue") +
labs(
title = "Taxi Trip Counts by Hour of Day",
x = "Hour (0–23)",
y = "Number of Trips"
) +
theme_minimal()
# Close PNG device to save file
dev.off()
# Plot payment type
png("outputs/Payment_type.png", width = 600, height = 500)
ggplot(payment_type_counts, aes(x = payment_type, y = n, fill = payment_type)) +
geom_col() +   # geom_col() is simpler for pre-summarized data
labs(
title = "Distribution of Payment Types",
x = "Payment Type",
y = "Count"
) +
theme_minimal() +
theme(legend.position = "none")
dev.off()
message("All outputs have been saved in /skills_demo_nyc/outputs")
required_pkgs <- c(
"DBI", "RMariaDB", "dplyr", "lubridate", "zoo", "SPEI", "reshape2",
"FAOSTAT", "data.table", "jsonlite", "tidyr", "naniar", "readr",
"ggplot2", "skimr", "corrplot", "scales", "janitor", "renv"
)
for (pkg in required_pkgs) {
if (!requireNamespace(pkg, quietly = TRUE)) {
install.packages(pkg, repos = "https://cran.rstudio.com")
}
library(pkg, character.only = TRUE)
}
setwd("C:/Users/vikgh/Desktop/STAT5129_GroupD_Project")
renv::init()
renv::snapshot()
file.exists("renv.lock")
ls(env)           # default: shows all objects
renv::restore()
